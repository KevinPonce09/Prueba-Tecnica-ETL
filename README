# ETL con PySpark - Prueba T茅cnica Ingeniero de Datos

## Descripci贸n
Este proyecto implementa una aplicaci贸n ETL en **PySpark**, capaz de procesar datos desde un archivo Excel (`Films2.xlsx`), realizar transformaciones, verificar la calidad de los datos y almacenar los resultados en formato CSV.

## Requisitos
Antes de ejecutar el proyecto, aseg煤rate de tener instalado lo siguiente:

- Python 3.8+
- Apache Spark
- Librer铆as necesarias (instalar con pip):
  ```sh
  pip install pyspark openpyxl
  ```

## Estructura del Proyecto
```
ETL_Spark_Project/
 etl_spark.py  # C贸digo principal de la ETL
 Films2.xlsx   # Archivo de datos (aseg煤rate de colocarlo en la ra铆z)
 output/       # Carpeta donde se guardar谩 el CSV procesado
 README.md     # Documentaci贸n del proyecto
 informe.md    # An谩lisis y resultados de la ETL
```

## Ejecuci贸n
Para ejecutar el pipeline ETL, usa el siguiente comando:
```sh
python etl_spark.py
```

## Justificaci贸n del Dise帽o
- **Escalabilidad:** Uso de **PySpark** para manejar grandes vol煤menes de datos.
- **Modularidad:** Separaci贸n de responsabilidades (extracci贸n, transformaci贸n, validaci贸n y carga).
- **Buenas pr谩cticas:** Implementaci贸n de **POO y SOLID**.
- **Observabilidad:** Uso de **logs** para rastrear la ejecuci贸n.

## Resultados
El resultado final del procesamiento se guarda en `output/films_processed/` en formato **CSV**, listo para ser utilizado en an谩lisis o integraci贸n con otros sistemas.

## Contacto
Si tienes dudas o mejoras, cont谩ctame. 

